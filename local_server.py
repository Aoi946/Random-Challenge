#!/usr/bin/env python3
"""
ãƒ­ãƒ¼ã‚«ãƒ«ã‚µãƒ¼ãƒãƒ¼ - Pythonåˆ†é¡æ©Ÿã‚’ç›´æ¥ä½¿ç”¨ã™ã‚‹Webã‚¢ãƒ—ãƒª
"""

from flask import Flask, render_template, request, jsonify, send_from_directory
import sys
import os
sys.path.append('./exported_classifier')
sys.path.append('./checker')

from calculate_features import calculate_all_features
from randomness_checker import check_sequence_randomness, print_randomness_report
import pickle
import pandas as pd

app = Flask(__name__)

# åˆ†é¡æ©Ÿã‚’èµ·å‹•æ™‚ã«èª­ã¿è¾¼ã¿
classifier_data = None
model = None
scaler = None

def load_classifier():
    global classifier_data, model, scaler
    try:
        with open('./exported_classifier/human_machine_classifier.pkl', 'rb') as f:
            classifier_data = pickle.load(f)
        model = classifier_data['model']
        scaler = classifier_data['scaler']
        print("åˆ†é¡æ©Ÿèª­ã¿è¾¼ã¿å®Œäº†")
        return True
    except Exception as e:
        print(f"åˆ†é¡æ©Ÿèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return False

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/mt_figures/<filename>')
def serve_histogram(filename):
    """
    ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ç”»åƒã‚’æä¾›
    """
    return send_from_directory('./mt_figures', filename)

@app.route('/classify', methods=['POST'])
def classify():
    try:
        data = request.json
        sequence = data.get('sequence', [])

        if not sequence:
            return jsonify({'error': 'æ•°åˆ—ãŒç©ºã§ã™'})

        if len(sequence) < 10:
            return jsonify({'error': 'æ•°åˆ—ãŒçŸ­ã™ãã¾ã™ï¼ˆæœ€ä½10å€‹å¿…è¦ï¼‰'})

        # ç‰¹å¾´é‡è¨ˆç®—
        features = calculate_all_features(sequence)

        # äºˆæ¸¬å®Ÿè¡Œ
        features_scaled = scaler.transform(features)
        prediction = model.predict(features_scaled)[0]
        probabilities = model.predict_proba(features_scaled)[0]

        # äººé–“åˆ¤å®šã®å ´åˆã€è©³ç´°ãªãƒ©ãƒ³ãƒ€ãƒ æ€§åˆ†æã‚’å®Ÿè¡Œ
        randomness_analysis = None
        deviation_report = None

        if prediction == 1:  # äººé–“åˆ¤å®šã®å ´åˆ
            try:
                # çµ±è¨ˆãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’æŠ½å‡ºã—ã¦ãƒ©ãƒ³ãƒ€ãƒ æ€§ãƒã‚§ãƒƒã‚¯
                stat_metrics = extract_statistical_metrics(features)
                randomness_analysis = check_sequence_randomness(stat_metrics)
                deviation_report = generate_deviation_report(randomness_analysis, stat_metrics)
            except Exception as e:
                print(f"Randomness analysis error: {e}")

        # çµæœã‚’è¿”ã™
        result = {
            'success': True,
            'result': {
                'isHuman': bool(prediction == 1),
                'isMachineRandom': bool(prediction == 0),
                'verdict': 'human' if prediction == 1 else 'machine',
                'humanProbability': float(probabilities[1]),
                'machineProbability': float(probabilities[0]),
                'confidence': float(max(probabilities)),
                'rawPrediction': int(prediction)
            },
            'details': {
                'inputLength': len(sequence),
                'featuresCount': len(features.columns),
                'modelVersion': 'Python 527-feature classifier',
                'accuracy': '98.31%'
            },
            'feedback': generate_feedback(prediction == 1, max(probabilities)),
            'recommendations': generate_recommendations(prediction == 1),
            'randomnessAnalysis': randomness_analysis,
            'deviationReport': deviation_report
        }

        return jsonify(result)

    except Exception as e:
        return jsonify({'error': f'åˆ†é¡ã‚¨ãƒ©ãƒ¼: {str(e)}'})

def generate_feedback(is_human, confidence):
    feedback = []

    if is_human:
        if confidence > 0.8:
            feedback.append('ğŸ” æ˜ã‚‰ã‹ã«äººé–“ãŒç”Ÿæˆã—ãŸãƒ‘ã‚¿ãƒ¼ãƒ³ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ')
            feedback.append('äººé–“ç‰¹æœ‰ã®èªçŸ¥ãƒã‚¤ã‚¢ã‚¹ã‚„ç„¡æ„è­˜ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒå¼·ãç¾ã‚Œã¦ã„ã¾ã™')
        elif confidence > 0.6:
            feedback.append('ğŸ‘¤ äººé–“ã‚‰ã—ã„ç‰¹å¾´ãŒè¦‹ã‚‰ã‚Œã¾ã™')
            feedback.append('ã„ãã¤ã‹ã®äººé–“çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ')
        else:
            feedback.append('â“ ã‚ãšã‹ã«äººé–“ã‚‰ã—ã„å‚¾å‘ãŒè¦‹ã‚‰ã‚Œã¾ã™')
            feedback.append('æ©Ÿæ¢°çš„ãƒ©ãƒ³ãƒ€ãƒ æ€§ã«è¿‘ã„ã§ã™ãŒã€å¾®ç´°ãªäººé–“çš„ç‰¹å¾´ãŒã‚ã‚Šã¾ã™')
    else:
        if confidence > 0.8:
            feedback.append('ğŸ‰ ç´ æ™´ã‚‰ã—ã„ï¼ãƒ¡ãƒ«ã‚»ãƒ³ãƒŒãƒ„ã‚¤ã‚¹ã‚¿ãƒ¼ç´šã®ãƒ©ãƒ³ãƒ€ãƒ æ€§ã§ã™ï¼')
            feedback.append('æ©Ÿæ¢°çš„ãªçœŸä¹±æ•°ç”Ÿæˆå™¨ã¨åŒç­‰ã®é«˜å“è³ªãªç„¡ä½œç‚ºæ€§ã‚’å®Ÿç¾ã—ã¦ã„ã¾ã™')
        elif confidence > 0.6:
            feedback.append('âœ¨ å„ªã‚ŒãŸãƒ©ãƒ³ãƒ€ãƒ æ€§ã‚’ç¤ºã—ã¦ã„ã¾ã™')
            feedback.append('ã‚ãšã‹ãªäººé–“çš„ç‰¹å¾´ã¯ã‚ã‚Šã¾ã™ãŒã€å…¨ä½“çš„ã«è‰¯å¥½ãªç„¡ä½œç‚ºæ€§ã§ã™')
        else:
            feedback.append('âš–ï¸ æ©Ÿæ¢°çš„ãƒ©ãƒ³ãƒ€ãƒ æ€§ã«è¿‘ã„çµæœã§ã™')
            feedback.append('äººé–“çš„ãªç‰¹å¾´ã‚‚å«ã¾ã‚Œã¦ã„ã¾ã™ãŒã€æ¯”è¼ƒçš„è‰¯å¥½ãªç„¡ä½œç‚ºæ€§ã§ã™')

    return feedback

def generate_recommendations(is_human):
    recommendations = []

    if is_human:
        recommendations.extend([
            'ğŸ¯ ã‚ˆã‚ŠçœŸã®ãƒ©ãƒ³ãƒ€ãƒ ã«è¿‘ã¥ã‘ã‚‹ãŸã‚ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹:',
            '',
            'ğŸ“‹ åŸºæœ¬åŸå‰‡:',
            'â€¢ æ„è­˜çš„ã«ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é¿ã‘ã‚ˆã†ã¨ã—ã™ããªã„ã§ãã ã•ã„',
            'â€¢ å„æ•°å­—ã‚’ç­‰é »åº¦ã§ä½¿ãŠã†ã¨æ„è­˜ã—ã™ããªã„ã§ãã ã•ã„',
            'â€¢ å‰ã«é¸ã‚“ã æ•°å­—ã®ã“ã¨ã¯å¿˜ã‚Œã¦ã€ç´”ç²‹ã«ç›´æ„Ÿã§é¸ã‚“ã§ãã ã•ã„',
            'â€¢ ã€Œãƒ©ãƒ³ãƒ€ãƒ ã£ã½ãè¦‹ãˆã‚‹ã€æ•°åˆ—ã‚’ä½œã‚ã†ã¨ã—ãªã„ã§ãã ã•ã„',
            '',
            'ğŸ’¡ å®Ÿè·µçš„ãªãƒ’ãƒ³ãƒˆ:',
            'â€¢ ç›®ã‚’é–‰ã˜ã¦ã€é ­ã«æµ®ã‹ã‚“ã æ•°å­—ã‚’ãã®ã¾ã¾å…¥åŠ›ã™ã‚‹',
            'â€¢ æ™‚è¨ˆã®ç§’æ•°ã‚„ãƒ©ãƒ³ãƒ€ãƒ ãªç’°å¢ƒéŸ³ã‚’å‚è€ƒã«ã™ã‚‹',
            'â€¢ ã‚µã‚¤ã‚³ãƒ­ã‚„ã‚³ã‚¤ãƒ³ãªã©ã®ç‰©ç†çš„ãƒ©ãƒ³ãƒ€ãƒ æ€§ã‚’æ´»ç”¨ã™ã‚‹'
        ])
    else:
        recommendations.extend([
            'ğŸ† ãŠã‚ã§ã¨ã†ã”ã–ã„ã¾ã™ï¼',
            'ã‚ãªãŸã®æ•°åˆ—ã¯æ©Ÿæ¢°çš„ãªçœŸä¹±æ•°ç”Ÿæˆå™¨ã«åŒ¹æ•µã™ã‚‹é«˜å“è³ªãªãƒ©ãƒ³ãƒ€ãƒ æ€§ã‚’å®Ÿç¾ã—ã¦ã„ã¾ã™ã€‚',
            '',
            'âœ¨ ã“ã®æˆæœã®æ„å‘³:',
            'â€¢ äººé–“ã®ç›´æ„Ÿçš„ãƒ©ãƒ³ãƒ€ãƒ æ€§ã¨ã—ã¦éå¸¸ã«å„ªç§€ã§ã™',
            'â€¢ çµ±è¨ˆçš„ã«æœ‰æ„ãªåã‚Šã‚„ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒã»ã¨ã‚“ã©æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ',
            'â€¢ ã“ã®ãƒ¬ãƒ™ãƒ«ã®ç„¡ä½œç‚ºæ€§ã‚’ä¸€è²«ã—ã¦ç¶­æŒã™ã‚‹ã®ã¯æ¥µã‚ã¦å›°é›£ã§ã™'
        ])

    return recommendations

def extract_statistical_metrics(features):
    """
    527ç‰¹å¾´é‡ã‹ã‚‰çµ±è¨ˆãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆ27å€‹ï¼‰ã‚’æŠ½å‡ºã—ã¦checkerç”¨ã«å¤‰æ›
    """
    # ç‰¹å¾´é‡DataFrameã‹ã‚‰çµ±è¨ˆãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’æŠ½å‡º
    metrics = {}

    # åŸºæœ¬çµ±è¨ˆé‡
    if 'redundancy' in features.columns:
        metrics['redundancy'] = float(features['redundancy'].iloc[0])
    if 'coupon_mean' in features.columns:
        metrics['coupon_mean'] = float(features['coupon_mean'].iloc[0])
    if 'coupon_std' in features.columns:
        metrics['coupon_std'] = float(features['coupon_std'].iloc[0])
    if 'repetition_gap_mean' in features.columns:
        metrics['repetition_gap_mean'] = float(features['repetition_gap_mean'].iloc[0])
    if 'repetition_gap_std' in features.columns:
        metrics['repetition_gap_std'] = float(features['repetition_gap_std'].iloc[0])
    if 'adjacent' in features.columns:
        metrics['adjacent'] = float(features['adjacent'].iloc[0])
    if 'tpi' in features.columns:
        metrics['tpi'] = float(features['tpi'].iloc[0])
    if 'autocorr_lag1' in features.columns:
        metrics['autocorr_lag1'] = float(features['autocorr_lag1'].iloc[0])
    if 'adjacent_diff_mean' in features.columns:
        metrics['adjacent_diff_mean'] = float(features['adjacent_diff_mean'].iloc[0])
    if 'adjacent_diff_std' in features.columns:
        metrics['adjacent_diff_std'] = float(features['adjacent_diff_std'].iloc[0])
    if 'max_min_ratio' in features.columns:
        metrics['max_min_ratio'] = float(features['max_min_ratio'].iloc[0])
    if 'rp' in features.columns:
        metrics['rp'] = float(features['rp'].iloc[0])

    # ãƒãƒ¼ã‚«ãƒ¼ãƒ†ã‚¹ãƒˆ
    for i in range(1, 6):
        col = f'pl{i}'
        if col in features.columns:
            metrics[col] = float(features[col].iloc[0])

    # é »åº¦
    for i in range(10):
        col = f'freq_{i}'
        if col in features.columns:
            metrics[col] = float(features[col].iloc[0])

    return metrics

def generate_deviation_report(randomness_analysis, stat_metrics):
    """
    ãƒ©ãƒ³ãƒ€ãƒ æ€§åˆ†æçµæœã‹ã‚‰è©³ç´°ãªé€¸è„±ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
    """
    if not randomness_analysis:
        return None

    # å¢ƒç•Œå€¤ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    bounds_df = load_bounds_table()

    report = {
        'summary': {
            'total_metrics': len(stat_metrics),
            'outliers_count': len(randomness_analysis.get('outliers', [])),
            'within_bounds_count': len(randomness_analysis.get('within_bounds', [])),
            'is_random': len(randomness_analysis.get('outliers', [])) == 0
        },
        'outliers': [],
        'improvements': []
    }

    # å¤–ã‚Œå€¤ã®è©³ç´°åˆ†æ
    for outlier in randomness_analysis.get('outliers', []):
        metric_name = outlier['metric']
        actual_value = outlier['value']

        # çµ±è¨ˆçš„æœŸå¾…ç¯„å›²ã‚’è¨ˆç®—
        expected_range = calculate_statistical_range(metric_name, bounds_df)

        outlier_info = {
            'metric': metric_name,
            'actual': actual_value,
            'expected_min': expected_range.get('lower'),
            'expected_max': expected_range.get('upper'),
            'expected_mean': expected_range.get('mean'),
            'deviation_type': 'high' if actual_value > expected_range.get('upper', float('inf')) else 'low',
            'explanation': get_metric_explanation(metric_name),
            'improvement_tip': get_improvement_tip(metric_name, actual_value, expected_range),
            'histogram_url': f'/mt_figures/{metric_name}_histogram.png',
            'detailed_explanation': get_detailed_metric_explanation(metric_name)
        }
        report['outliers'].append(outlier_info)

    # æ”¹å–„ææ¡ˆã®ç”Ÿæˆ
    report['improvements'] = generate_improvement_suggestions(report['outliers'])

    return report

def load_bounds_table():
    """
    å¢ƒç•Œå€¤ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’èª­ã¿è¾¼ã¿
    """
    try:
        bounds_path = './checker/mt_randomness_bounds.csv'
        return pd.read_csv(bounds_path)
    except FileNotFoundError:
        print("Warning: bounds table not found")
        return None

def calculate_statistical_range(metric_name, bounds_df, confidence_level=0.95):
    """
    çµ±è¨ˆçš„æœŸå¾…ç¯„å›²ã‚’è¨ˆç®—ï¼ˆæ­£è¦åˆ†å¸ƒä»®å®šã§ã®ä¿¡é ¼åŒºé–“ï¼‰
    """
    if bounds_df is None:
        return {'lower': None, 'upper': None, 'mean': None}

    metric_row = bounds_df[bounds_df['metric'] == metric_name]
    if metric_row.empty:
        return {'lower': None, 'upper': None, 'mean': None}

    row = metric_row.iloc[0]
    mean = row['expected_mean']
    std = row['expected_std']

    # æ­£è¦åˆ†å¸ƒã‚’ä»®å®šã—ã¦ä¿¡é ¼åŒºé–“ã‚’è¨ˆç®—
    if confidence_level == 0.95:
        # 95%ä¿¡é ¼åŒºé–“ (Â±1.96Ïƒ)
        z_score = 1.96
    elif confidence_level == 0.99:
        # 99%ä¿¡é ¼åŒºé–“ (Â±2.58Ïƒ)
        z_score = 2.58
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ95%
        z_score = 1.96

    # ä¸€éƒ¨ã®æŒ‡æ¨™ã¯æ­£è¦åˆ†å¸ƒã§ãªã„å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§ã€å¹³å‡å€¤ã®ã¿ä½¿ç”¨
    non_normal_metrics = ['pl3', 'pl4', 'pl5', 'max_min_ratio']

    if metric_name in non_normal_metrics:
        # éæ­£è¦åˆ†å¸ƒ: å¹³å‡å€¤ã®ã¿
        return {
            'lower': mean,
            'upper': mean,
            'mean': mean
        }
    else:
        # æ­£è¦åˆ†å¸ƒä»®å®š: ä¿¡é ¼åŒºé–“ã‚’è¨ˆç®—
        margin = z_score * std
        return {
            'lower': mean - margin,
            'upper': mean + margin,
            'mean': mean
        }

def get_metric_explanation(metric_name):
    """
    ãƒ¡ãƒˆãƒªã‚¯ã‚¹åã«åŸºã¥ã„ã¦ç°¡æ½”ãªèª¬æ˜ã‚’è¿”ã™
    """
    explanations = {
        'redundancy': 'å†—é•·æ€§ï¼ˆæƒ…å ±ã®äºˆæ¸¬å¯èƒ½æ€§ï¼‰',
        'coupon_mean': 'ã‚¯ãƒ¼ãƒãƒ³ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼å¹³å‡ï¼ˆå…¨æ•°å­—åé›†åŠ¹ç‡ï¼‰',
        'coupon_std': 'ã‚¯ãƒ¼ãƒãƒ³ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼æ¨™æº–åå·®ï¼ˆåé›†å®‰å®šæ€§ï¼‰',
        'repetition_gap_mean': 'ç¹°ã‚Šè¿”ã—é–“éš”å¹³å‡ï¼ˆåŒæ•°å­—å†å‡ºç¾é–“éš”ï¼‰',
        'repetition_gap_std': 'ç¹°ã‚Šè¿”ã—é–“éš”æ¨™æº–åå·®ï¼ˆé–“éš”ã®ã°ã‚‰ã¤ãï¼‰',
        'adjacent': 'éš£æ¥é †åºã‚¹ã‚³ã‚¢ï¼ˆé€£ç¶šãƒ‘ã‚¿ãƒ¼ãƒ³é »åº¦ï¼‰',
        'tpi': 'ã‚¿ãƒ¼ãƒ‹ãƒ³ã‚°ãƒã‚¤ãƒ³ãƒˆæŒ‡æ•°ï¼ˆå¢—æ¸›è»¢æ›ç‚¹é »åº¦ï¼‰',
        'autocorr_lag1': '1æ¬¡è‡ªå·±ç›¸é–¢ï¼ˆå‰æ•°å­—ã¨ã®é–¢é€£æ€§ï¼‰',
        'adjacent_diff_mean': 'éš£æ¥å·®åˆ†å¹³å‡ï¼ˆéš£æ¥æ•°å­—ã®å·®ï¼‰',
        'adjacent_diff_std': 'éš£æ¥å·®åˆ†æ¨™æº–åå·®ï¼ˆå·®ã®ã°ã‚‰ã¤ãï¼‰',
        'max_min_ratio': 'æœ€å¤§æœ€å°é »åº¦æ¯”ï¼ˆæ•°å­—ä½¿ç”¨ã®åã‚Šï¼‰',
        'rp': 'ãƒªãƒ”ãƒ¼ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³æŒ‡æ¨™ï¼ˆåŒä¸€ãƒ‘ã‚¿ãƒ¼ãƒ³ç¹°ã‚Šè¿”ã—ï¼‰',
        'pl1': 'ãƒ•ã‚§ãƒ¼ã‚ºé•·1ï¼ˆã‚¿ãƒ¼ãƒ‹ãƒ³ã‚°ãƒã‚¤ãƒ³ãƒˆé–“è·é›¢1ï¼‰',
        'pl2': 'ãƒ•ã‚§ãƒ¼ã‚ºé•·2ï¼ˆã‚¿ãƒ¼ãƒ‹ãƒ³ã‚°ãƒã‚¤ãƒ³ãƒˆé–“è·é›¢2ï¼‰',
        'pl3': 'ãƒ•ã‚§ãƒ¼ã‚ºé•·3ï¼ˆã‚¿ãƒ¼ãƒ‹ãƒ³ã‚°ãƒã‚¤ãƒ³ãƒˆé–“è·é›¢3ï¼‰',
        'pl4': 'ãƒ•ã‚§ãƒ¼ã‚ºé•·4ï¼ˆã‚¿ãƒ¼ãƒ‹ãƒ³ã‚°ãƒã‚¤ãƒ³ãƒˆé–“è·é›¢4ï¼‰',
        'pl5': 'ãƒ•ã‚§ãƒ¼ã‚ºé•·5ï¼ˆã‚¿ãƒ¼ãƒ‹ãƒ³ã‚°ãƒã‚¤ãƒ³ãƒˆé–“è·é›¢5ï¼‰',
    }

    # é »åº¦ç³»ã®èª¬æ˜
    for i in range(10):
        explanations[f'freq_{i}'] = f'æ•°å­—{i}ã®å‡ºç¾é »åº¦ï¼ˆç†æƒ³ã¯10%ï¼‰'

    return explanations.get(metric_name, f'{metric_name}ã®çµ±è¨ˆçš„æŒ‡æ¨™')

def get_detailed_metric_explanation(metric_name):
    """
    ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è©³ç´°èª¬æ˜ã‚’è¿”ã™
    """
    detailed_explanations = {
        'redundancy': {
            'title': 'å†—é•·æ€§ (Redundancy)',
            'description': 'ã‚·ãƒ£ãƒãƒ³ã®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ç†è«–ã«åŸºã¥ãæŒ‡æ¨™ã§ã€ä¹±æ•°åˆ—ãŒã©ã‚Œã ã‘å†—é•·ï¼ˆäºˆæ¸¬å¯èƒ½ï¼‰ã§ã‚ã‚‹ã‹ã‚’æ¸¬å®šã—ã¾ã™ã€‚',
            'formula': '1 - (å®Ÿéš›ã®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ / æœ€å¤§ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼)',
            'range': '0.0 ã€œ 1.0',
            'interpretation': '0.0: å®Œå…¨ã«ãƒ©ãƒ³ãƒ€ãƒ ï¼ˆç†æƒ³çš„ï¼‰ / 1.0: å®Œå…¨ã«äºˆæ¸¬å¯èƒ½'
        },
        'coupon_mean': {
            'title': 'ã‚¯ãƒ¼ãƒãƒ³ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼å•é¡Œ (Coupon Collector)',
            'description': 'å…¨ã¦ã®æ•°å­—ï¼ˆ0ã€œ9ï¼‰ã‚’å°‘ãªãã¨ã‚‚1å›ãšã¤é›†ã‚ã‚‹ãŸã‚ã«å¿…è¦ãªé€£ç¶šã—ãŸæ•°å­—ã®å¹³å‡å€‹æ•°ã‚’æ¸¬å®šã—ã¾ã™ã€‚',
            'formula': 'å„ä½ç½®ã‹ã‚‰å§‹ã‚ã¦å…¨ã¦ã®æ•°å­—ãŒå‡ºç¾ã™ã‚‹ã¾ã§ã®é•·ã•ã®å¹³å‡',
            'range': 'ç†è«–çš„æœ€å°å€¤ã¯ç´„29.29',
            'interpretation': 'å°ã•ã„å€¤ï¼ˆã€œ30ï¼‰: ãƒ©ãƒ³ãƒ€ãƒ æ€§ãŒé«˜ã„ / å¤§ãã„å€¤ï¼ˆ50ä»¥ä¸Šï¼‰: ç‰¹å®šæ•°å­—ãŒå‡ºç¾ã—ã«ãã„'
        },
        'repetition_gap_mean': {
            'title': 'ç¹°ã‚Šè¿”ã—é–“éš” (Repetition Gap)',
            'description': 'åŒã˜æ•°å­—ãŒå†ã³å‡ºç¾ã™ã‚‹ã¾ã§ã®å¹³å‡é–“éš”ã‚’æ¸¬å®šã—ã¾ã™ã€‚',
            'formula': 'åŒã˜æ•°å­—ã®é€£ç¶šã™ã‚‹å‡ºç¾ä½ç½®ã®å·®ã®å¹³å‡',
            'range': '1.0ã€œ10.0',
            'interpretation': '10ã«è¿‘ã„å€¤: ãƒ©ãƒ³ãƒ€ãƒ æ€§ãŒé«˜ã„ / å°ã•ã„å€¤: åŒã˜æ•°å­—ãŒé »ç¹ã«è¿‘æ¥å‡ºç¾'
        },
        'adjacent': {
            'title': 'éš£æ¥é †åºã‚¹ã‚³ã‚¢ (Adjacent Order Score)',
            'description': 'é€£ç¶šã™ã‚‹æ•°å­—ãŒ+1ã¾ãŸã¯-1ã®å·®ã‚’æŒã¤é »åº¦ã‚’æ¸¬å®šã—ã¾ã™ã€‚',
            'formula': '(n+1ã¾ãŸã¯n-1ã®éš£æ¥ãƒšã‚¢æ•°) / (å…¨ãƒšã‚¢æ•°)',
            'range': '0.0 ã€œ 1.0',
            'interpretation': 'é«˜ã„å€¤: é€£ç¶šãƒ‘ã‚¿ãƒ¼ãƒ³ãŒå¤šã„ï¼ˆ1,2,3...ï¼‰ / ä½ã„å€¤: éš£æ¥æ•°å€¤ã®é€£ç¶šæ€§ãŒå°‘ãªã„'
        },
        'tpi': {
            'title': 'ã‚¿ãƒ¼ãƒ‹ãƒ³ã‚°ãƒã‚¤ãƒ³ãƒˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ (Turning Point Index)',
            'description': 'æ•°åˆ—ãŒå¢—åŠ ã‹ã‚‰æ¸›å°‘ã€ã¾ãŸã¯æ¸›å°‘ã‹ã‚‰å¢—åŠ ã«åˆ‡ã‚Šæ›¿ã‚ã‚‹é »åº¦ã‚’æ¸¬å®šã—ã¾ã™ã€‚',
            'formula': 'å®Ÿéš›ã®ã‚¿ãƒ¼ãƒ‹ãƒ³ã‚°ãƒã‚¤ãƒ³ãƒˆæ•° / æœŸå¾…ã‚¿ãƒ¼ãƒ‹ãƒ³ã‚°ãƒã‚¤ãƒ³ãƒˆæ•°',
            'range': '0.0ä»¥ä¸Šï¼ˆç†æƒ³çš„ã«ã¯1.0ä»˜è¿‘ï¼‰',
            'interpretation': '1.0ä»˜è¿‘: ãƒ©ãƒ³ãƒ€ãƒ åˆ—ã¨åŒç­‰ / >1.0: æŒ¯å‹•ãŒå¤šã„ / <1.0: å‚¾å‘ãŒç¶šã'
        },
        'autocorr_lag1': {
            'title': 'è‡ªå·±ç›¸é–¢ (Lag-1 Autocorrelation)',
            'description': 'æ•°åˆ—å†…ã®å„å€¤ã¨ãã®ç›´å‰ã®å€¤ã¨ã®é–“ã®ç·šå½¢é–¢ä¿‚ã‚’æ¸¬å®šã—ã¾ã™ã€‚',
            'formula': 'ãƒ©ã‚°1ã®è‡ªå·±ç›¸é–¢ä¿‚æ•°',
            'range': '-1.0 ã€œ 1.0',
            'interpretation': '0ã«è¿‘ã„: å‰å¾Œã®æ•°å­—ã«ç›¸é–¢ãªã—ï¼ˆç†æƒ³çš„ï¼‰ / æ­£å€¤: ä¼¼ãŸå‚¾å‘ / è² å€¤: é€†ã®å‚¾å‘'
        },
        'max_min_ratio': {
            'title': 'æœ€å¤§ãƒ»æœ€å°é »åº¦æ¯” (Max-Min Frequency Ratio)',
            'description': 'æ•°åˆ—å†…ã§ã®å„æ•°å­—ã®å‡ºç¾é »åº¦ã®æœ€å¤§å€¤ã¨æœ€å°å€¤ã®æ¯”ç‡ã‚’æ¸¬å®šã—ã¾ã™ã€‚',
            'formula': 'æœ€é »å‡ºæ•°å­—ã®é »åº¦ / æœ€å°‘å‡ºç¾æ•°å­—ã®é »åº¦',
            'range': '1.0ä»¥ä¸Š',
            'interpretation': '1.0ã«è¿‘ã„: å…¨æ•°å­—ãŒå‡ç­‰å‡ºç¾ï¼ˆç†æƒ³çš„ï¼‰ / å¤§ãã„å€¤: æ¥µç«¯ãªåã‚Šã‚ã‚Š'
        },
        'rp': {
            'title': 'ãƒªãƒ”ãƒ¼ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³æŒ‡æ¨™ (Repeat Pattern)',
            'description': 'éš£æ¥2æ–‡å­—ãƒšã‚¢ï¼ˆãƒã‚¤ã‚°ãƒ©ãƒ ï¼‰ãŒç¹°ã‚Šè¿”ã—å‡ºç¾ã™ã‚‹åº¦åˆã„ã‚’æ¸¬å®šã—ã¾ã™ã€‚',
            'formula': '1 - (ä¸€åº¦ã—ã‹ç¾ã‚Œãªã„ãƒã‚¤ã‚°ãƒ©ãƒ æ•° / å…¨ãƒã‚¤ã‚°ãƒ©ãƒ æ•°)',
            'range': '0.0 ã€œ 1.0',
            'interpretation': 'ä½ã„å€¤: ãƒ‘ã‚¿ãƒ¼ãƒ³ç¹°ã‚Šè¿”ã—å°‘ãªããƒ©ãƒ³ãƒ€ãƒ æ€§é«˜ã„ / é«˜ã„å€¤: ãƒ‘ã‚¿ãƒ¼ãƒ³ç¹°ã‚Šè¿”ã—å¤šã„'
        }
    }

    # ãƒ•ã‚§ãƒ¼ã‚ºé•·ç³»ã®è©³ç´°èª¬æ˜
    for i in range(1, 6):
        detailed_explanations[f'pl{i}'] = {
            'title': f'ãƒ•ã‚§ãƒ¼ã‚ºé•·æŒ‡æ¨™ {i} (Phase Length {i})',
            'description': f'ã‚¿ãƒ¼ãƒ‹ãƒ³ã‚°ãƒã‚¤ãƒ³ãƒˆé–“ã®è·é›¢ãŒ{i}ã§ã‚ã‚‹å ´åˆã®å‡ºç¾é »åº¦ã‚’æ¸¬å®šã—ã¾ã™ã€‚',
            'formula': f'è¦³æ¸¬ã•ã‚ŒãŸãƒ•ã‚§ãƒ¼ã‚ºé•·{i} / æœŸå¾…ãƒ•ã‚§ãƒ¼ã‚ºé•·{i}',
            'range': '0.0ä»¥ä¸Šï¼ˆç†æƒ³çš„ã«ã¯1.0ä»˜è¿‘ï¼‰',
            'interpretation': f'1.0ä»˜è¿‘: ãƒ©ãƒ³ãƒ€ãƒ åˆ—ã¨åŒç­‰ / >1.0: è·é›¢{i}ã®TPãŒéå‰° / <1.0: è·é›¢{i}ã®TPãŒä¸è¶³'
        }

    # é »åº¦ç³»ã®è©³ç´°èª¬æ˜
    for i in range(10):
        detailed_explanations[f'freq_{i}'] = {
            'title': f'æ•°å­—{i}ã®å‡ºç¾é »åº¦ (Digit {i} Frequency)',
            'description': f'æ•°å­—{i}ã®æ­£è¦åŒ–ã•ã‚ŒãŸå‡ºç¾é »åº¦ã‚’æ¸¬å®šã—ã¾ã™ã€‚',
            'formula': f'æ•°å­—{i}ã®å‡ºç¾å›æ•° / æ•°åˆ—ã®é•·ã•',
            'range': '0.0 ã€œ 1.0',
            'interpretation': 'ç†æƒ³çš„ãªãƒ©ãƒ³ãƒ€ãƒ ã§ã¯0.1ï¼ˆ10%ï¼‰ã§å‡ºç¾ã€‚åã‚ŠãŒã‚ã‚‹ã¨é«˜ä½ãŒç”Ÿã˜ã‚‹'
        }

    return detailed_explanations.get(metric_name, {
        'title': metric_name,
        'description': 'çµ±è¨ˆçš„æŒ‡æ¨™',
        'formula': 'N/A',
        'range': 'N/A',
        'interpretation': 'N/A'
    })

def get_improvement_tip(metric_name, actual_value, expected_range):
    """
    å…·ä½“çš„ãªæ”¹å–„ææ¡ˆã‚’ç”Ÿæˆ
    """
    if metric_name.startswith('freq_'):
        digit = metric_name.split('_')[1]
        if actual_value > expected_range.get('upper', 0.12):
            return f'æ•°å­—{digit}ã‚’{actual_value*100:.1f}%ä½¿ç”¨ï¼ˆç†æƒ³10%ï¼‰ã€‚ç„¡æ„è­˜ã«å¥½ã‚€æ•°å­—ã‚’é¿ã‘ã€ä»–ã®æ•°å­—ã‚‚æ„è­˜çš„ã«é¸ã‚“ã§ãã ã•ã„'
        else:
            return f'æ•°å­—{digit}ã‚’{actual_value*100:.1f}%ã—ã‹ä½¿ç”¨ï¼ˆç†æƒ³10%ï¼‰ã€‚ã“ã®æ•°å­—ã‚’é¿ã‘ã‚‹å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚æ„è­˜çš„ã«ä½¿ã£ã¦ãã ã•ã„'

    elif metric_name == 'redundancy':
        if actual_value > expected_range.get('upper', 0.02):
            return 'æƒ…å ±ãŒäºˆæ¸¬å¯èƒ½ã™ãã¾ã™ã€‚è¦å‰‡æ€§ã‚„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ„è­˜ã›ãšã€ç´”ç²‹ã«æ€ã„æµ®ã‹ã‚“ã æ•°å­—ã‚’é¸ã‚“ã§ãã ã•ã„'

    elif metric_name == 'adjacent':
        if actual_value > expected_range.get('upper', 0.25):
            return 'é€£ç¶šã™ã‚‹æ•°å­—ï¼ˆ1â†’2ã€7â†’6ãªã©ï¼‰ã‚’å¤šç”¨ã—ã¦ã„ã¾ã™ã€‚æ•°å­—ã‚’é¸ã¶æ™‚ã«å‰ã®æ•°å­—ã‚’ç„¡è¦–ã—ã¦ãã ã•ã„'

    elif metric_name == 'autocorr_lag1':
        if abs(actual_value) > 0.15:
            direction = 'å¤§ãã„æ•°å­—ã®å¾Œã«å¤§ãã„æ•°å­—' if actual_value > 0 else 'å¤§ãã„æ•°å­—ã®å¾Œã«å°ã•ã„æ•°å­—'
            return f'å‰ã®æ•°å­—ã¨ã®ç›¸é–¢ãŒå¼·ã™ãã¾ã™ï¼ˆ{direction}ã‚’é¸ã¶å‚¾å‘ï¼‰ã€‚å‰ã®æ•°å­—ã‚’å®Œå…¨ã«å¿˜ã‚Œã¦æ¬¡ã‚’é¸ã‚“ã§ãã ã•ã„'

    elif metric_name == 'tpi':
        if actual_value > expected_range.get('upper', 1.1):
            return 'ã‚¿ãƒ¼ãƒ‹ãƒ³ã‚°ãƒã‚¤ãƒ³ãƒˆï¼ˆå¢—æ¸›è»¢æ›ï¼‰ãŒå¤šã™ãã¾ã™ã€‚æ„å›³çš„ãªä¸Šä¸‹å¤‰å‹•ã‚’é¿ã‘ã€è‡ªç„¶ã«æ•°å­—ã‚’é¸ã‚“ã§ãã ã•ã„'
        elif actual_value < expected_range.get('lower', 0.8):
            return 'ã‚¿ãƒ¼ãƒ‹ãƒ³ã‚°ãƒã‚¤ãƒ³ãƒˆãŒå°‘ãªã™ãã¾ã™ã€‚ä¸€å®šæ–¹å‘ã¸ã®å‚¾å‘ãŒå¼·ã„ã®ã§ã€ã‚‚ã£ã¨å¤‰åŒ–ã‚’ã¤ã‘ã¦ãã ã•ã„'

    elif metric_name == 'max_min_ratio':
        if actual_value > expected_range.get('upper', 2.5):
            return 'ç‰¹å®šã®æ•°å­—ã«åã‚Šã™ãã¦ã„ã¾ã™ã€‚å«Œã„ãªæ•°å­—ã‚„å¥½ããªæ•°å­—ã‚’æ„è­˜ã›ãšã€ã™ã¹ã¦ã®æ•°å­—ã‚’å‡ç­‰ã«ä½¿ã£ã¦ãã ã•ã„'

    elif metric_name == 'rp':
        if actual_value > expected_range.get('upper', 1.05):
            return 'åŒã˜æ•°å­—ãƒšã‚¢ã‚’ç¹°ã‚Šè¿”ã—ã™ãã¦ã„ã¾ã™ã€‚ç›´å‰ã®2æ¡ã‚’å¿˜ã‚Œã¦ã€å®Œå…¨ã«æ–°ã—ã„æ•°å­—ã‚’é¸ã‚“ã§ãã ã•ã„'

    elif metric_name.startswith('pl'):
        phase_num = metric_name[2]
        if actual_value > expected_range.get('upper', 1.2):
            return f'ãƒ•ã‚§ãƒ¼ã‚ºé•·{phase_num}ã®å‘¨æœŸãƒ‘ã‚¿ãƒ¼ãƒ³ãŒéå‰°ã§ã™ã€‚{phase_num}å€‹ã”ã¨ã®è¦å‰‡æ€§ã‚’é¿ã‘ã€å®Œå…¨ã«ãƒ©ãƒ³ãƒ€ãƒ ã«é¸ã‚“ã§ãã ã•ã„'

    elif metric_name in ['coupon_mean', 'coupon_std']:
        if 'mean' in metric_name and actual_value > expected_range.get('upper', 35):
            return 'å…¨æ•°å­—ã®åé›†ãŒéåŠ¹ç‡ã§ã™ã€‚å«Œã„ãªæ•°å­—ã‚„é¿ã‘ãŒã¡ãªæ•°å­—ã‚’æ„è­˜çš„ã«ä½¿ã£ã¦ãã ã•ã„'
        elif 'std' in metric_name and actual_value > expected_range.get('upper', 15):
            return 'æ•°å­—åé›†ã®å®‰å®šæ€§ãŒä½ã„ã§ã™ã€‚ç‰¹å®šã®æ•°å­—ã‚’é›†ä¸­çš„ã«ä½¿ã‚ãšã€ãƒãƒ©ãƒ³ã‚¹ã‚ˆãé¸ã‚“ã§ãã ã•ã„'

    elif metric_name.startswith('repetition_gap'):
        if 'mean' in metric_name and actual_value < expected_range.get('lower', 8):
            return 'åŒã˜æ•°å­—ã‚’è¿‘ãã§ç¹°ã‚Šè¿”ã—ã™ãã¦ã„ã¾ã™ã€‚ä¸€åº¦ä½¿ã£ãŸæ•°å­—ã‚’ã—ã°ã‚‰ãé¿ã‘ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“'

    elif metric_name.startswith('adjacent_diff'):
        if 'mean' in metric_name and actual_value < expected_range.get('lower', 3.0):
            return 'éš£æ¥ã™ã‚‹æ•°å­—ã®å·®ãŒå°ã•ã™ãã¾ã™ã€‚è¿‘ã„æ•°å­—ã°ã‹ã‚Šé¸ã°ãšã€é›¢ã‚ŒãŸæ•°å­—ã‚‚é¸ã‚“ã§ãã ã•ã„'

    return 'å„æ•°å­—ã‚’å¹³ç­‰ã«æ‰±ã„ã€å‰ã®é¸æŠã‚’å¿˜ã‚Œã¦ç´”ç²‹ã«ãƒ©ãƒ³ãƒ€ãƒ ã«é¸ã‚“ã§ãã ã•ã„'

def generate_improvement_suggestions(outliers):
    """
    å¤–ã‚Œå€¤æƒ…å ±ã‹ã‚‰ç·åˆçš„ãªæ”¹å–„ææ¡ˆã‚’ç”Ÿæˆ
    """
    suggestions = []

    # é »åº¦ã®åã‚Šãƒã‚§ãƒƒã‚¯
    freq_outliers = [o for o in outliers if o['metric'].startswith('freq_')]
    if len(freq_outliers) > 3:
        favorite_digits = [o['metric'].split('_')[1] for o in freq_outliers if o['deviation_type'] == 'high']
        avoided_digits = [o['metric'].split('_')[1] for o in freq_outliers if o['deviation_type'] == 'low']

        suggestion = 'ğŸ¯ æ•°å­—ã®ä½¿ç”¨ã«å¼·ã„åã‚ŠãŒã‚ã‚Šã¾ã™ã€‚'
        if favorite_digits:
            suggestion += f' æ•°å­—{",".join(favorite_digits)}ã‚’å¤šç”¨ã—ã€'
        if avoided_digits:
            suggestion += f' æ•°å­—{",".join(avoided_digits)}ã‚’é¿ã‘ã‚‹å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚'
        suggestion += ' å¥½ãå«Œã„ã‚’æ„è­˜ã›ãšã€å…¨ã¦ã®æ•°å­—ã‚’å¹³ç­‰ã«æ‰±ã£ã¦ãã ã•ã„ã€‚'
        suggestions.append(suggestion)

    # ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨è¦å‰‡æ€§ãƒã‚§ãƒƒã‚¯
    pattern_outliers = [o for o in outliers if o['metric'] in ['adjacent', 'rp', 'pl1', 'pl2', 'pl3']]
    if len(pattern_outliers) >= 2:
        suggestions.append('ğŸ”„ è¤‡æ•°ã®è¦å‰‡çš„ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒæ¤œå‡ºã•ã‚Œã¦ã„ã¾ã™ã€‚ã€Œãƒ©ãƒ³ãƒ€ãƒ ã‚‰ã—ãè¦‹ã›ã‚ˆã†ã€ã¨æ„è­˜ã›ãšã€ç´”ç²‹ã«é ­ã«æµ®ã‹ã‚“ã æ•°å­—ã‚’ãã®ã¾ã¾å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚')

    # ç›¸é–¢ã¨ä¾å­˜æ€§ãƒã‚§ãƒƒã‚¯
    dependency_outliers = [o for o in outliers if o['metric'] in ['autocorr_lag1', 'adjacent', 'repetition_gap_mean']]
    if len(dependency_outliers) >= 2:
        suggestions.append('ğŸ”— å‰ã®é¸æŠãŒæ¬¡ã®é¸æŠã«å½±éŸ¿ã—ã¦ã„ã¾ã™ã€‚æ•°å­—ã‚’é¸ã¶æ™‚ã¯ã€ã“ã‚Œã¾ã§ã«ä½•ã‚’é¸ã‚“ã ã‹ã‚’å®Œå…¨ã«å¿˜ã‚Œã€æ¯å›æ–°é®®ãªæ°—æŒã¡ã§é¸ã‚“ã§ãã ã•ã„ã€‚')

    # å¤‰å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
    variation_outliers = [o for o in outliers if o['metric'] in ['tpi', 'adjacent_diff_mean', 'adjacent_diff_std']]
    if len(variation_outliers) >= 2:
        suggestions.append('ğŸ“Š æ•°å­—ã®å¤‰å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã«åã‚ŠãŒã‚ã‚Šã¾ã™ã€‚æ„å›³çš„ã«å¤§ããå¤‰åŒ–ã•ã›ãŸã‚Šã€ä¼¼ãŸæ•°å­—ã‚’ç¶šã‘ãŸã‚Šã›ãšã€è‡ªç„¶ãªé¸æŠã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚')

    # å†—é•·æ€§ãƒã‚§ãƒƒã‚¯
    if any(o['metric'] == 'redundancy' for o in outliers):
        suggestions.append('ğŸ² æƒ…å ±ã®äºˆæ¸¬å¯èƒ½æ€§ãŒé«˜ã™ãã¾ã™ã€‚æˆ¦ç•¥çš„ã«è€ƒãˆãšã«ã€ã‚³ã‚¤ãƒ³ã‚’æŠ•ã’ã‚‹ã‚ˆã†ãªç´”ç²‹ãªå¶ç„¶æ€§ã§æ•°å­—ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚')

    # åŠ¹ç‡æ€§ãƒã‚§ãƒƒã‚¯
    collection_outliers = [o for o in outliers if o['metric'].startswith('coupon')]
    if len(collection_outliers) > 0:
        suggestions.append('ğŸ“¦ æ•°å­—ã®åé›†åŠ¹ç‡ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ç‰¹å®šã®æ•°å­—ã‚’ç„¡æ„è­˜ã«é¿ã‘ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å«Œã„ãªæ•°å­—ã‚‚æ„è­˜çš„ã«ä½¿ã£ã¦ãã ã•ã„ã€‚')

    # ãƒ•ã‚§ãƒ¼ã‚ºé•·ãƒã‚§ãƒƒã‚¯
    phase_outliers = [o for o in outliers if o['metric'].startswith('pl')]
    if len(phase_outliers) >= 2:
        phases = [o['metric'][2] for o in phase_outliers]
        suggestions.append(f'ğŸ”¢ ãƒ•ã‚§ãƒ¼ã‚ºé•·{",".join(phases)}ã«å‘¨æœŸçš„ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒã‚ã‚Šã¾ã™ã€‚{len(phases)}ç¨®é¡ã®å‘¨æœŸæ€§ãŒæ¤œå‡ºã•ã‚Œã¦ã„ã‚‹ã®ã§ã€ã‚ˆã‚Šä¸è¦å‰‡ãªé¸æŠã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚')

    if not suggestions:
        suggestions.append('ğŸ’¡ çµ±è¨ˆçš„ã«ã¯è»½å¾®ãªåã‚Šã®ã¿ã§ã™ã€‚ã•ã‚‰ã«æ”¹å–„ã™ã‚‹ã«ã¯ã€æ•°å­—é¸æŠæ™‚ã«ä¸€åˆ‡ã®æ„å›³ã‚„æˆ¦ç•¥ã‚’æ’é™¤ã—ã€å®Œå…¨ã«ç„¡æ„è­˜ã§é¸ã‚“ã§ãã ã•ã„ã€‚')

    return suggestions

if __name__ == '__main__':
    if not load_classifier():
        print("åˆ†é¡æ©Ÿã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
        sys.exit(1)

    print("ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ä¸­...")
    print("ãƒ–ãƒ©ã‚¦ã‚¶ã§ http://localhost:5000 ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦ãã ã•ã„")
    app.run(debug=True, host='0.0.0.0', port=5000)